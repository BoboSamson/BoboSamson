{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12a57c18",
   "metadata": {},
   "source": [
    "1.   ### The The original implementation used:\n",
    "\n",
    "Multi-GPU training     \n",
    "Dense Prediction   \n",
    "Model Parallelism (split across GPUs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ace260",
   "metadata": {},
   "source": [
    "2.   ### Full ImageNet training used:\n",
    "\n",
    "1.2M training images\n",
    "\n",
    "50K validation images\n",
    "\n",
    "Multi-scale training (256-512px random resizing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad9e53f",
   "metadata": {},
   "source": [
    "3.   ### Modern implementations often:\n",
    "\n",
    "Use Adam instead of SGD    \n",
    "Apply batch normalization    \n",
    "Use different LR schedules     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a46dd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(VGG16, self).__init__()\n",
    "        \n",
    "        # Feature extraction (convolutional blocks)\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1 (64 channels)\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 224x224 -> 112x112\n",
    "            \n",
    "            # Block 2 (128 channels)\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 112x112 -> 56x56\n",
    "            \n",
    "            # Block 3 (256 channels)\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 56x56 -> 28x28\n",
    "            \n",
    "            # Block 4 (512 channels)\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 28x28 -> 14x14\n",
    "            \n",
    "            # Block 5 (512 channels)\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 14x14 -> 7x7\n",
    "        )\n",
    "        \n",
    "        # Classifier (fully connected layers)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),  # Original first FC layer\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),  # Original dropout rate\n",
    "            \n",
    "            nn.Linear(4096, 4096),  # Original second FC layer\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            \n",
    "            nn.Linear(4096, num_classes),  # Final classification layer\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)  # Conv blocks\n",
    "        x = torch.flatten(x, 1)  # Flatten to [batch_size, 512*7*7]\n",
    "        x = self.classifier(x)  # FC layers\n",
    "        return x\n",
    "\n",
    "# Instantiate the full model\n",
    "vgg16 = VGG16()\n",
    "\n",
    "# Print architecture summary\n",
    "print(vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0c96c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1. Data Loading & Preprocessing (Original Paper Setup)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),        # Multi-scale training\n",
    "    transforms.RandomHorizontalFlip(),        # Paper's augmentation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet mean\n",
    "                         std=[0.229, 0.224, 0.225])   # ImageNet std\n",
    "])\n",
    "\n",
    "# (Replace with actual ImageNet path)\n",
    "train_dataset = datasets.ImageFolder(root='/path/to/imagenet/train', \n",
    "                                   transform=train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=256, shuffle=True, num_workers=4)\n",
    "\n",
    "# 2. Model Initialization (Original Config)\n",
    "model = VGG16(num_classes=1000)  # Using previous VGG16 class\n",
    "\n",
    "# 3. Weight Initialization (Glorot/Bengio 2010)\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        if m.bias is not None: nn.init.constant_(m.bias, 0)\n",
    "model.apply(init_weights)\n",
    "\n",
    "# 4. Loss & Optimizer (Paper's Exact Parameters)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), \n",
    "                     lr=0.01,           # Initial learning rate\n",
    "                     momentum=0.9, \n",
    "                     weight_decay=5e-4)  # L2 penalty\n",
    "\n",
    "# 5. Learning Rate Scheduler (Paper's 3-step decrease)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, \n",
    "                             patience=1, verbose=True)  # Val acc plateaus\n",
    "\n",
    "# 6. Training Loop (Simplified version of paper's 74-epoch setup)\n",
    "total_iterations = 0\n",
    "for epoch in range(74):  # Total epochs from paper\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        total_iterations += 1\n",
    "    \n",
    "    # Validation (simplified - paper used 50K val images)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Actual validation code would go here\n",
    "        val_acc = 0.0  # Placeholder for real validation\n",
    "    \n",
    "    # Paper's learning rate schedule\n",
    "    scheduler.step(val_acc)  # Monitor validation accuracy\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/74 | Loss: {epoch_loss/len(train_loader):.4f} | \"\n",
    "          f\"LR: {optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "    # Early stopping at 370K iterations (74 epochs * 5007 iterations/epoch)\n",
    "    if total_iterations >= 370000:\n",
    "        break\n",
    "\n",
    "# 7. Final Model Saving\n",
    "torch.save(model.state_dict(), 'vgg16_imagenet.pth')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
